{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loan Approval Prediction Competition\n",
    "The goal for this competition is to predict whether an applicant is approved for a loan.\n",
    "\n",
    "Submissions are evaluated using area under the ROC curve using the predicted probabilities and the ground truth targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import cross_validate, KFold, train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Overview and Feature Exploration\n",
    "\n",
    "Before we explore what models may be suitible or well performing, lets establish what data we have and what format it is in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/merged_dataset.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['person_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df):\n",
    "    df = df.copy()\n",
    "    if 'id' in df.columns:\n",
    "        df.drop('id', axis=1, inplace=True)\n",
    "    df['age_squared'] = df['person_age'] ** 2\n",
    "    df['is_young'] = (df['person_age'] < 30).astype(int)\n",
    "    \n",
    "    df['income_log'] = np.log1p(df['person_income'])\n",
    "    df['high_income'] = (df['person_income'] > df['person_income'].median()).astype(int)\n",
    "    \n",
    "    df = pd.get_dummies(df, columns=['person_home_ownership'], prefix='home_ownership')\n",
    "    \n",
    "    df['emp_length_log'] = np.log1p(df['person_emp_length'])\n",
    "    df['is_experienced'] = (df['person_emp_length'] > 5).astype(int)\n",
    "    \n",
    "    df = pd.get_dummies(df, columns=['loan_intent'], prefix='intent')\n",
    "\n",
    "    \n",
    "    grade_order = {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7}\n",
    "    df['loan_grade_ordinal'] = df['loan_grade'].map(grade_order)\n",
    "    df.drop('loan_grade', axis=1, inplace=True)\n",
    "    \n",
    "    df['loan_amnt_log'] = np.log1p(df['loan_amnt'])\n",
    "    df['loan_amnt_to_income'] = df['loan_amnt'] / df['person_income']\n",
    "   \n",
    "    df['int_rate_squared'] = df['loan_int_rate'] ** 2\n",
    "    \n",
    "    df['high_percent_income'] = (df['loan_percent_income'] > 0.2).astype(int)\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    df['default_history_encoded'] = le.fit_transform(df['cb_person_default_on_file'])\n",
    "    df.drop('cb_person_default_on_file', axis=1, inplace=True)\n",
    "    \n",
    "    df['cred_hist_length_log'] = np.log1p(df['cb_person_cred_hist_length'])\n",
    "    df['<5years_credit_history'] = (df['cb_person_cred_hist_length'] < 5).astype(int)\n",
    "    \n",
    "    df['income_emp_length_interaction'] = df['income_log'] * df['emp_length_log']\n",
    "    df['loan_amnt_int_rate_interaction'] = df['loan_amnt_log'] * df['loan_int_rate']\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_train = engineer_features(train_df)\n",
    "engineered_test = engineer_features(test_df)\n",
    "engineered_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is the data clean? are there any errors or bias?\n",
    "We can see there are no null values in the dataset now lets move onto the spread of the data to see any bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_counts_train = train_df.isnull().sum()\n",
    "null_counts_test = test_df.isnull().sum()\n",
    "\n",
    "null_counts_combined = pd.concat([null_counts_train, null_counts_test], axis=1)\n",
    "null_counts_combined.columns = ['Train', 'Test']\n",
    "\n",
    "null_counts_combined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now looking at the spread of how many loans are given, we can see there are far more loans rejected than accepted meaning:\n",
    "- An evaluation metric such as accuracy is likely to perform poorly as if you predicted rejected for all loans then you would score an accuracy of 85.7%. \n",
    "- This inbalance in the dataset may mean that stratified sampling may be useful if cross validaiton is used.\n",
    "- AUC ROC is a good starting point for the evaluation metric as it is also the metric chosen by the competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(data=train_df, hue='loan_status')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First trying with PCA to see if there is a linear relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(engineered_train.drop('loan_status', axis=1))\n",
    "\n",
    "pca = PCA(n_components=len(engineered_train.columns) - 1)\n",
    "pca_result = pca.fit_transform(df_scaled)\n",
    "\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(f\"Explained Variance Ratio by each component: {explained_variance}\")\n",
    "\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(np.cumsum(explained_variance), linestyle='-', color='b', label='Cumulative Variance Explained')\n",
    "plt.axhline(y=0.95, color='red', linestyle='--', label='95% Variance Threshold')\n",
    "\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.ylim(0, 1)\n",
    "plt.xlim(0, len(explained_variance)-1)\n",
    "plt.title('Explained Variance by Principal Components')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(x = range(1, len(explained_variance)+1), height=explained_variance)\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.ylim(0, 1)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting (e.g., XGBoost, LightGBM, CatBoost):\n",
    "- Pros: Great for structured/tabular data, handles non-linear relationships very well, and has built-in feature selection. Generally, boosted trees perform better than \n",
    "Random Forests on complex tasks.\n",
    "- Cons: Requires more tuning and is more computationally intensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = engineered_train.drop(columns=['loan_status'])\n",
    "y = engineered_train['loan_status']\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "def objective(space):\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc',\n",
    "        'eta': space['eta'],\n",
    "        'max_depth': int(space['max_depth']),\n",
    "        'subsample': space['subsample'],\n",
    "        'colsample_bytree': space['colsample_bytree'],\n",
    "        'alpha': space['alpha'],\n",
    "        'lambda': space['lambda'],\n",
    "        'n_estimators': int(space['n_estimators']),\n",
    "        'seed': 42\n",
    "    }\n",
    "    \n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    \n",
    "    cv_results = cross_validate(model, X_scaled, y, cv=kf, scoring='roc_auc', return_train_score=True)\n",
    "    mean_test_auc = np.mean(cv_results['test_score'])\n",
    "    mean_train_auc = np.mean(cv_results['train_score'])\n",
    "    \n",
    "    return {'loss': -mean_test_auc, 'status': STATUS_OK, 'train_auc': mean_train_auc, 'test_auc': mean_test_auc}\n",
    "\n",
    "space = {\n",
    "    'eta': hp.loguniform('eta', np.log(0.001), np.log(0.1)),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 10, 1),\n",
    "    'subsample': hp.uniform('subsample', 0.6, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.6, 1.0),\n",
    "    'alpha': hp.loguniform('alpha', np.log(1e-8), np.log(1.0)),\n",
    "    'lambda': hp.loguniform('lambda', np.log(1e-8), np.log(1.0)),\n",
    "    'n_estimators': hp.quniform('n_estimators', 100, 1000, 50)\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "best_hyperparams = fmin(fn=objective,\n",
    "                        space=space,\n",
    "                        algo=tpe.suggest,\n",
    "                        max_evals=200,\n",
    "                        trials=trials)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_hyperparams)\n",
    "print(\"Best Test AUC:\", -trials.best_trial['result']['loss'])\n",
    "print(\"Corresponding Train AUC:\", trials.best_trial['result']['train_auc'])\n",
    "\n",
    "\n",
    "best_params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'eta': best_hyperparams['eta'],\n",
    "    'max_depth': int(best_hyperparams['max_depth']),\n",
    "    'subsample': best_hyperparams['subsample'],\n",
    "    'colsample_bytree': best_hyperparams['colsample_bytree'],\n",
    "    'alpha': best_hyperparams['alpha'],\n",
    "    'lambda': best_hyperparams['lambda'],\n",
    "    'n_estimators': int(best_hyperparams['n_estimators']),\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "final_model = xgb.XGBClassifier(**best_params)\n",
    "final_model.fit(X_scaled, y)\n",
    "\n",
    "\n",
    "feature_importance = final_model.feature_importances_\n",
    "feature_names = X.columns\n",
    "for importance, name in sorted(zip(feature_importance, feature_names), reverse=True):\n",
    "    print(f\"{name}: {importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = engineered_test\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "y_pred_prob = final_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "\n",
    "predictions_df = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'loan_status': y_pred_prob\n",
    "})\n",
    "\n",
    "predictions_df.to_csv('../submission/loan_predictions.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved to 'submission/loan_predictions.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
